<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Advanced Video Transcription Studio</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #f5f5f5;
            color: #333;
            line-height: 1.6;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        .header {
            text-align: center;
            margin-bottom: 30px;
        }

        .header h1 {
            color: #2c3e50;
            margin-bottom: 10px;
        }

        .api-config {
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            margin-bottom: 30px;
        }

        .config-grid {
            display: grid;
            grid-template-columns: 1fr 1fr 1fr;
            gap: 15px;
            margin-bottom: 15px;
        }

        .config-group {
            display: flex;
            flex-direction: column;
        }

        .config-group label {
            font-weight: 600;
            margin-bottom: 5px;
            color: #555;
        }

        .config-group input, .config-group select {
            padding: 10px;
            border: 2px solid #e1e8ed;
            border-radius: 6px;
            font-size: 14px;
            transition: border-color 0.2s;
        }

        .config-group input:focus, .config-group select:focus {
            outline: none;
            border-color: #3498db;
        }

        .upload-section {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            margin-bottom: 30px;
        }

        .upload-area {
            border: 3px dashed #bdc3c7;
            border-radius: 10px;
            padding: 40px;
            text-align: center;
            cursor: pointer;
            transition: all 0.3s;
            background: #fafafa;
        }

        .upload-area:hover {
            border-color: #3498db;
            background: #f8f9fa;
        }

        .upload-area.dragover {
            border-color: #2ecc71;
            background: #e8f8f5;
        }

        .upload-icon {
            font-size: 48px;
            color: #bdc3c7;
            margin-bottom: 20px;
        }

        .file-info {
            background: #e8f4fd;
            border: 1px solid #bee5eb;
            border-radius: 8px;
            padding: 15px;
            margin-top: 15px;
            display: none;
        }

        .processing-section {
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            margin-bottom: 30px;
            display: none;
        }

        .process-steps {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin-bottom: 20px;
        }

        .process-step {
            padding: 15px;
            border-radius: 8px;
            text-align: center;
            transition: all 0.3s;
        }

        .process-step.pending {
            background: #f8f9fa;
            border: 2px solid #e9ecef;
        }

        .process-step.processing {
            background: #fff3cd;
            border: 2px solid #ffeaa7;
        }

        .process-step.completed {
            background: #d4edda;
            border: 2px solid #c3e6cb;
        }

        .process-step.error {
            background: #f8d7da;
            border: 2px solid #f5c6cb;
        }

        .progress-bar {
            width: 100%;
            height: 20px;
            background: #e9ecef;
            border-radius: 10px;
            overflow: hidden;
            margin: 15px 0;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #3498db, #2ecc71);
            width: 0%;
            transition: width 0.3s;
        }

        .transcript-container {
            display: grid;
            grid-template-columns: 400px 1fr;
            gap: 30px;
            background: white;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            overflow: hidden;
            display: none;
        }

        .media-panel {
            background: #2c3e50;
            padding: 25px;
            color: white;
        }

        .media-controls {
            margin-bottom: 20px;
        }

        .media-controls audio {
            width: 100%;
            margin-bottom: 15px;
        }

        .playback-controls {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 10px;
            margin-bottom: 15px;
        }

        .control-btn {
            padding: 8px 12px;
            border: none;
            border-radius: 6px;
            background: #34495e;
            color: white;
            cursor: pointer;
            font-size: 12px;
            transition: background 0.2s;
        }

        .control-btn:hover {
            background: #4a6278;
        }

        .control-btn.active {
            background: #3498db;
        }

        .export-controls {
            border-top: 1px solid #34495e;
            padding-top: 20px;
        }

        .export-controls h4 {
            margin-bottom: 15px;
            color: #ecf0f1;
        }

        .export-btn {
            display: block;
            width: 100%;
            padding: 10px;
            margin-bottom: 8px;
            border: none;
            border-radius: 6px;
            background: #27ae60;
            color: white;
            cursor: pointer;
            transition: background 0.2s;
        }

        .export-btn:hover {
            background: #2ecc71;
        }

        .transcript-panel {
            padding: 25px;
            overflow-y: auto;
            max-height: 70vh;
        }

        .transcript-header {
            display: flex;
            justify-content: between;
            align-items: center;
            margin-bottom: 20px;
            padding-bottom: 15px;
            border-bottom: 1px solid #e1e8ed;
        }

        .search-box {
            flex: 1;
            padding: 8px 12px;
            border: 1px solid #e1e8ed;
            border-radius: 6px;
            margin-right: 10px;
        }

        .transcript-content {
            line-height: 1.8;
        }

        .speaker-segment {
            margin-bottom: 20px;
            padding-bottom: 15px;
            border-bottom: 1px solid #f1f3f4;
        }

        .speaker-label {
            font-weight: 700;
            color: #2c3e50;
            margin-bottom: 8px;
            cursor: pointer;
            display: inline-block;
            padding: 4px 8px;
            border-radius: 4px;
            background: #ecf0f1;
        }

        .speaker-label:hover {
            background: #d5dbdb;
        }

        .transcript-text {
            margin-bottom: 5px;
        }

        .transcript-word {
            cursor: pointer;
            padding: 2px 1px;
            border-radius: 3px;
            transition: all 0.2s;
            position: relative;
        }

        .transcript-word:hover {
            background: #f8f9fa;
        }

        .transcript-word.current {
            background: #ffeb3b;
            font-weight: 600;
            box-shadow: 0 2px 4px rgba(255,235,59,0.4);
        }

        .transcript-word.low-confidence {
            background: #ffebee;
            border-bottom: 2px solid #f44336;
        }

        .timestamp {
            font-size: 11px;
            color: #95a5a6;
            margin-left: 5px;
        }

        .confidence-indicator {
            display: inline-block;
            width: 8px;
            height: 8px;
            border-radius: 50%;
            margin-left: 3px;
            vertical-align: middle;
        }

        .confidence-high { background: #2ecc71; }
        .confidence-medium { background: #f39c12; }
        .confidence-low { background: #e74c3c; }

        .loading-spinner {
            border: 3px solid #f3f3f3;
            border-top: 3px solid #3498db;
            border-radius: 50%;
            width: 30px;
            height: 30px;
            animation: spin 1s linear infinite;
            display: inline-block;
            margin-right: 10px;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .error-message {
            background: #f8d7da;
            border: 1px solid #f5c6cb;
            color: #721c24;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }

        .success-message {
            background: #d4edda;
            border: 1px solid #c3e6cb;
            color: #155724;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }

        @media (max-width: 768px) {
            .config-grid {
                grid-template-columns: 1fr;
            }
            
            .transcript-container {
                grid-template-columns: 1fr;
            }
            
            .media-panel {
                order: 2;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>🎬 Advanced Video Transcription Studio</h1>
            <p>Professional video transcription with speaker diarization and interactive editing</p>
        </div>

        <!-- API Configuration -->
        <div class="api-config">
            <h3 style="margin-bottom: 20px;">🔑 API Configuration</h3>
            <div class="config-grid">
                <div class="config-group">
                    <label for="transcription-service">Transcription Service</label>
                    <select id="transcription-service">
                        <option value="assemblayai">AssemblyAI (Transcription + Speaker Diarization)</option>
                        <option value="openai">OpenAI gpt-4o-transcribe (Transcription Only)</option>
                    </select>
                </div>
                <div class="config-group">
                    <label for="api-key">API Key</label>
                    <input type="password" id="api-key" placeholder="Enter your API key" />
                </div>
                <div class="config-group">
                    <label for="language">Language</label>
                    <select id="language">
                        <option value="en">English</option>
                        <option value="ar">Arabic (العربية)</option>
                        <option value="auto">Auto-detect</option>
                    </select>
                </div>
            </div>
            <div class="config-grid">
                <div class="config-group">
                    <label for="speaker-diarization">Enable Speaker Diarization</label>
                    <select id="speaker-diarization">
                        <option value="true">Yes</option>
                        <option value="false">No</option>
                    </select>
                </div>
                <div class="config-group">
                    <label for="word-timestamps">Word-level Timestamps</label>
                    <select id="word-timestamps">
                        <option value="true">Yes</option>
                        <option value="false">No</option>
                    </select>
                </div>
                <div class="config-group">
                    <label for="audio-quality">Audio Quality</label>
                    <select id="audio-quality">
                        <option value="high">High (22kHz, 128kbps)</option>
                        <option value="medium">Medium (16kHz, 96kbps)</option>
                        <option value="low">Low (16kHz, 64kbps)</option>
                    </select>
                </div>
                <div class="config-group">
                    <label for="speaker-count">Number of Speakers</label>
                    <input type="number" id="speaker-count" min="1" value="2" />
                </div>
                <div class="config-group">
                    <label for="speaker-names">Speaker Names (comma separated)</label>
                    <input type="text" id="speaker-names" placeholder="Alice,Bob" />
                </div>
            </div>
        </div>

        <!-- File Upload -->
        <div class="upload-section">
            <h3 style="margin-bottom: 20px;">📁 Upload Media File</h3>
            <div class="upload-area" id="upload-area">
                <div class="upload-icon">🎥</div>
                <h4>Click to upload or drag and drop</h4>
                <p>Supports most audio and video formats</p>
                <input type="file" id="video-input" accept="video/*,audio/*" style="display: none;" />
            </div>
            <div class="file-info" id="file-info"></div>
        </div>

        <!-- Processing Status -->
        <div class="processing-section" id="processing-section">
            <h3 style="margin-bottom: 20px;">⚙️ Processing Status</h3>
            <div class="process-steps">
                <div class="process-step pending" id="step-extract">
                    <h4>1. Audio Extraction</h4>
                    <p>Extracting audio from video</p>
                </div>
                <div class="process-step pending" id="step-transcribe">
                    <h4>2. Transcription</h4>
                    <p>Converting speech to text</p>
                </div>
                <div class="process-step pending" id="step-diarize">
                    <h4>3. Speaker Analysis</h4>
                    <p>Identifying different speakers</p>
                </div>
                <div class="process-step pending" id="step-format">
                    <h4>4. Formatting</h4>
                    <p>Preparing interactive transcript</p>
                </div>
            </div>
            <div class="progress-bar">
                <div class="progress-fill" id="progress-fill"></div>
            </div>
            <div id="status-message"></div>
        </div>

        <!-- Transcript Interface -->
        <div class="transcript-container" id="transcript-container">
            <div class="media-panel">
                <div class="media-controls">
                    <audio id="audio-player" controls>
                        Your browser does not support the audio element.
                    </audio>
                    
                    <div class="playback-controls">
                        <button class="control-btn" id="play-on-click-btn">🎯 Click to Play</button>
                        <button class="control-btn" id="auto-scroll-btn">📜 Auto Scroll</button>
                        <button class="control-btn" id="speed-05x">0.5x</button>
                        <button class="control-btn" id="speed-1x">1x</button>
                        <button class="control-btn active" id="speed-15x">1.5x</button>
                        <button class="control-btn" id="speed-2x">2x</button>
                    </div>
                </div>

                <div class="export-controls">
                    <h4>📤 Export Options</h4>
                    <button class="export-btn" id="export-txt">Plain Text (.txt)</button>
                    <button class="export-btn" id="export-srt">SubRip (.srt)</button>
                    <button class="export-btn" id="export-vtt">WebVTT (.vtt)</button>
                    <button class="export-btn" id="export-json">JSON Data (.json)</button>
                    <button class="export-btn" id="export-html">HTML Report (.html)</button>
                </div>
            </div>

            <div class="transcript-panel">
                <div class="transcript-header">
                    <input type="text" class="search-box" id="search-box" placeholder="Search transcript..." />
                    <span id="word-count">0 words</span>
                </div>
                <div class="transcript-content" id="transcript-content">
                    <!-- Transcript content will be populated here -->
                </div>
            </div>
        </div>
    </div>

    <!-- External Dependencies -->
    <script src="https://unpkg.com/@ffmpeg/ffmpeg@0.12.7/dist/esm/index.js" type="module"></script>
    <script src="https://unpkg.com/@ffmpeg/util@0.12.1/dist/esm/index.js" type="module"></script>

    <script type="module">
        import { FFmpeg } from 'https://unpkg.com/@ffmpeg/ffmpeg@0.12.7/dist/esm/index.js';
        import { fetchFile } from 'https://unpkg.com/@ffmpeg/util@0.12.1/dist/esm/index.js';

        class AdvancedTranscriptionStudio {
            constructor() {
                this.ffmpeg = new FFmpeg();
                this.currentFile = null;
                this.audioBlob = null;
                this.transcriptData = null;
                this.audioPlayer = null;
                this.currentWordIndex = -1;
                this.playOnClick = true;
                this.autoScroll = true;
                this.ffmpegLoaded = false;
                
                this.initializeElements();
                this.setupEventListeners();
                this.loadFFmpeg();
            }

            initializeElements() {
                // File upload elements
                this.uploadArea = document.getElementById('upload-area');
                this.videoInput = document.getElementById('video-input');
                this.fileInfo = document.getElementById('file-info');
                
                // Configuration elements
                this.transcriptionService = document.getElementById('transcription-service');
                this.apiKey = document.getElementById('api-key');
                this.language = document.getElementById('language');
                this.speakerDiarization = document.getElementById('speaker-diarization');
                this.wordTimestamps = document.getElementById('word-timestamps');
                this.audioQuality = document.getElementById('audio-quality');
                this.speakerCount = document.getElementById('speaker-count');
                this.speakerNames = document.getElementById('speaker-names');
                
                // Processing elements
                this.processingSection = document.getElementById('processing-section');
                this.progressFill = document.getElementById('progress-fill');
                this.statusMessage = document.getElementById('status-message');
                
                // Transcript elements
                this.transcriptContainer = document.getElementById('transcript-container');
                this.audioPlayer = document.getElementById('audio-player');
                this.transcriptContent = document.getElementById('transcript-content');
                this.searchBox = document.getElementById('search-box');
                this.wordCount = document.getElementById('word-count');
                
                // Control buttons
                this.playOnClickBtn = document.getElementById('play-on-click-btn');
                this.autoScrollBtn = document.getElementById('auto-scroll-btn');
            }

            async loadFFmpeg() {
                if (this.ffmpegLoaded) return;
                
                try {
                    this.ffmpeg.on('log', ({ message }) => {
                        console.log('FFmpeg:', message);
                    });

                    this.ffmpeg.on('progress', ({ progress }) => {
                        if (this.currentStep === 'extract') {
                            this.updateProgress(progress * 25); // Audio extraction is 25% of total
                        }
                    });

                    await this.ffmpeg.load();
                    this.ffmpegLoaded = true;
                    console.log('FFmpeg loaded successfully');
                } catch (error) {
                    console.error('Failed to load FFmpeg:', error);
                    this.showError('Failed to load video processing engine. Please refresh the page.');
                }
            }

            setupEventListeners() {
                // File upload
                this.uploadArea.addEventListener('click', () => this.videoInput.click());
                this.uploadArea.addEventListener('dragover', this.handleDragOver.bind(this));
                this.uploadArea.addEventListener('dragleave', this.handleDragLeave.bind(this));
                this.uploadArea.addEventListener('drop', this.handleDrop.bind(this));
                this.videoInput.addEventListener('change', this.handleFileSelect.bind(this));
                
                // Configuration changes
                this.transcriptionService.addEventListener('change', this.updateServiceOptions.bind(this));
                
                // Control buttons
                this.playOnClickBtn.addEventListener('click', this.togglePlayOnClick.bind(this));
                this.autoScrollBtn.addEventListener('click', this.toggleAutoScroll.bind(this));
                
                // Speed controls
                ['05x', '1x', '15x', '2x'].forEach(speed => {
                    document.getElementById(`speed-${speed}`).addEventListener('click', () => {
                        this.setPlaybackSpeed(speed.replace('x', '').replace('05', '0.5').replace('15', '1.5'));
                    });
                });
                
                // Export buttons
                ['txt', 'srt', 'vtt', 'json', 'html'].forEach(format => {
                    document.getElementById(`export-${format}`).addEventListener('click', () => {
                        this.exportTranscript(format);
                    });
                });
                
                // Search functionality
                this.searchBox.addEventListener('input', this.handleSearch.bind(this));
            }

            handleDragOver(e) {
                e.preventDefault();
                this.uploadArea.classList.add('dragover');
            }

            handleDragLeave(e) {
                e.preventDefault();
                this.uploadArea.classList.remove('dragover');
            }

            handleDrop(e) {
                e.preventDefault();
                this.uploadArea.classList.remove('dragover');
                const files = e.dataTransfer.files;
                if (files.length > 0) {
                    this.handleFileSelect({ target: { files } });
                }
            }

            handleFileSelect(e) {
                const file = e.target.files[0];
                if (!file) return;

                if (!this.validateFile(file)) return;

                this.currentFile = file;
                this.displayFileInfo(file);
                this.startProcessing();
            }

            validateFile(file) {
                const allowedTypes = [
                    'video/mp4', 'video/webm', 'video/avi', 'video/mov', 'video/quicktime',
                    'audio/mpeg', 'audio/wav', 'audio/mp3', 'audio/ogg', 'audio/x-wav'
                ];

                if (!allowedTypes.includes(file.type) && !file.type.startsWith('audio/') && !file.type.startsWith('video/')) {
                    this.showError('Please select a valid audio or video file');
                    return false;
                }

                return true;
            }

            displayFileInfo(file) {
                const fileSize = (file.size / 1024 / 1024).toFixed(2);
                this.fileInfo.innerHTML = `
                    <h4>📄 Selected File</h4>
                    <p><strong>Name:</strong> ${file.name}</p>
                    <p><strong>Size:</strong> ${fileSize} MB</p>
                    <p><strong>Type:</strong> ${file.type}</p>
                `;
                this.fileInfo.style.display = 'block';
            }

            async startProcessing() {
                if (!this.validateConfiguration()) return;

                await this.loadFFmpeg();

                this.processingSection.style.display = 'block';
                this.currentStep = 'extract';
                
                try {
                    // Step 1: Extract audio
                    await this.extractAudio();
                    
                    // Step 2: Transcribe audio
                    await this.transcribeAudio();
                    
                    // Step 3: Process transcript
                    await this.processTranscript();
                    
                    // Step 4: Display results
                    this.displayTranscript();
                    
                    this.showSuccess('Transcription completed successfully!');
                } catch (error) {
                    console.error('Processing failed:', error);
                    this.showError(`Processing failed: ${error.message}`);
                }
            }

            validateConfiguration() {
                if (!this.apiKey.value.trim()) {
                    this.showError('Please enter your API key');
                    return false;
                }
                return true;
            }

            async extractAudio() {
                this.updateStep('step-extract', 'processing');
                this.updateProgress(0, 'Extracting audio from video...');

                try {
                    const inputName = 'input_video';
                    const outputName = 'output_audio.wav';
                    
                    // Get quality settings
                    const quality = this.audioQuality.value;
                    const settings = this.getAudioQualitySettings(quality);

                    await this.ffmpeg.writeFile(inputName, await fetchFile(this.currentFile));
                    
                    await this.ffmpeg.exec([
                        '-i', inputName,
                        '-vn', // No video
                        '-acodec', 'pcm_s16le', // WAV format
                        '-ar', settings.sampleRate, // Sample rate
                        '-ac', '1', // Mono
                        outputName
                    ]);

                    const data = await this.ffmpeg.readFile(outputName);
                    this.audioBlob = new Blob([data.buffer], { type: 'audio/wav' });
                    
                    // Cleanup
                    await this.ffmpeg.deleteFile(inputName);
                    await this.ffmpeg.deleteFile(outputName);
                    
                    this.updateStep('step-extract', 'completed');
                    this.updateProgress(25, 'Audio extraction completed');
                    
                } catch (error) {
                    this.updateStep('step-extract', 'error');
                    throw new Error(`Audio extraction failed: ${error.message}`);
                }
            }

            getAudioQualitySettings(quality) {
                const settings = {
                    high: { sampleRate: '22050', bitRate: '128k' },
                    medium: { sampleRate: '16000', bitRate: '96k' },
                    low: { sampleRate: '16000', bitRate: '64k' }
                };
                return settings[quality] || settings.high;
            }

            async transcribeAudio() {
                this.updateStep('step-transcribe', 'processing');
                this.updateProgress(30, 'Sending audio for transcription...');

                const service = this.transcriptionService.value;

                try {
                    let result;
                    if (service === 'assemblayai') {
                        result = await this.transcribeWithAssemblyAI();
                    } else {
                        result = await this.transcribeWithOpenAI();
                    }

                    this.transcriptData = result;

                    this.updateStep('step-transcribe', 'completed');
                    this.updateProgress(70, 'Transcription completed');
                    
                } catch (error) {
                    this.updateStep('step-transcribe', 'error');
                    throw new Error(`Transcription failed: ${error.message}`);
                }
            }

            async transcribeWithAssemblyAI() {
                const apiKey = this.apiKey.value;
                const language = this.language.value === 'auto' ? null : this.language.value;
                
                // Upload audio file
                const uploadResponse = await fetch('https://api.assemblyai.com/v2/upload', {
                    method: 'POST',
                    headers: {
                        'Authorization': apiKey,
                        'Content-Type': 'application/octet-stream'
                    },
                    body: this.audioBlob
                });
                
                if (!uploadResponse.ok) {
                    throw new Error('Failed to upload audio to AssemblyAI');
                }
                
                const { upload_url } = await uploadResponse.json();
                
                // Request transcription
                const transcriptResponse = await fetch('https://api.assemblyai.com/v2/transcript', {
                    method: 'POST',
                    headers: {
                        'Authorization': apiKey,
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        audio_url: upload_url,
                        language_code: language,
                        speaker_labels: this.speakerDiarization.value === 'true',
                        word_timestamps: this.wordTimestamps.value === 'true',
                        punctuate: true,
                        format_text: true
                    })
                });
                
                if (!transcriptResponse.ok) {
                    throw new Error('Failed to request transcription from AssemblyAI');
                }
                
                const { id } = await transcriptResponse.json();

                // Poll for completion
                return await this.pollAssemblyAIResult(id, apiKey);
            }

            async pollAssemblyAIResult(transcriptId, apiKey) {
                const maxAttempts = 100;
                let attempts = 0;
                
                while (attempts < maxAttempts) {
                    const response = await fetch(`https://api.assemblyai.com/v2/transcript/${transcriptId}`, {
                        headers: {
                            'Authorization': apiKey
                        }
                    });
                    
                    if (!response.ok) {
                        throw new Error('Failed to check transcription status');
                    }
                    
                    const result = await response.json();
                    
                    if (result.status === 'completed') {
                        return this.formatAssemblyAIResult(result);
                    } else if (result.status === 'error') {
                        throw new Error(`Transcription failed: ${result.error}`);
                    }
                    
                    // Update progress
                    const progress = 30 + (attempts / maxAttempts) * 40;
                    this.updateProgress(progress, 'Processing transcription...');
                    
                    await new Promise(resolve => setTimeout(resolve, 3000));
                    attempts++;
                }
                
                throw new Error('Transcription timed out');
            }

            formatAssemblyAIResult(result) {
                const segments = [];
                let currentSpeaker = null;
                let currentSegment = null;
                
                result.words.forEach(word => {
                    if (word.speaker !== currentSpeaker) {
                        if (currentSegment) {
                            segments.push(currentSegment);
                        }
                        
                        currentSpeaker = word.speaker;
                        currentSegment = {
                            speaker: `Speaker ${word.speaker}`,
                            start: word.start / 1000,
                            end: word.end / 1000,
                            words: []
                        };
                    }
                    
                    currentSegment.words.push({
                        text: word.text,
                        start: word.start / 1000,
                        end: word.end / 1000,
                        confidence: word.confidence
                    });
                    
                    currentSegment.end = word.end / 1000;
                });
                
                if (currentSegment) {
                    segments.push(currentSegment);
                }
                
                return {
                    text: result.text,
                    segments: segments,
                    confidence: result.confidence,
                    language: result.language_code
                };
            }

            async transcribeWithOpenAI() {
                const apiKey = this.apiKey.value;
                const language = this.language.value === 'auto' ? undefined : this.language.value;
                
                const formData = new FormData();
                formData.append('file', this.audioBlob, 'audio.wav');
                formData.append('model', 'gpt-4o-transcribe');
                formData.append('response_format', 'verbose_json');
                formData.append('timestamp_granularities[]', 'word');
                if (this.speakerDiarization.value === 'true') {
                    formData.append('speaker_labels', 'true');
                }
                if (language) formData.append('language', language);
                
                const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${apiKey}`
                    },
                    body: formData
                });
                
                if (!response.ok) {
                    const error = await response.json();
                    throw new Error(error.error?.message || 'OpenAI transcription failed');
                }
                
                const result = await response.json();
                return this.formatOpenAIResult(result);
            }

            formatOpenAIResult(result) {
                if (result.segments) {
                    const segments = result.segments.map(seg => ({
                        speaker: `Speaker ${seg.speaker + 1}`,
                        start: seg.start,
                        end: seg.end,
                        words: seg.words.map(w => ({
                            text: w.word,
                            start: w.start,
                            end: w.end,
                            confidence: w.confidence || 0.9
                        }))
                    }));
                    return {
                        text: result.text,
                        segments,
                        confidence: result.segments.reduce((a, s) => a + (s.confidence || 0.9), 0) / result.segments.length,
                        language: result.language
                    };
                }

                const words = result.words || [];
                return {
                    text: result.text,
                    segments: [{
                        speaker: 'Speaker 1',
                        start: words[0]?.start || 0,
                        end: words[words.length - 1]?.end || 0,
                        words: words.map(word => ({
                            text: word.word,
                            start: word.start,
                            end: word.end,
                            confidence: 0.9
                        }))
                    }],
                    confidence: 0.9,
                    language: result.language
                };
            }

            async processTranscript() {
                this.updateStep('step-diarize', 'processing');
                this.updateProgress(75, 'Processing speaker information...');
                
                // Speaker information may already be included from the API
                
                this.updateStep('step-diarize', 'completed');
                this.updateStep('step-format', 'processing');
                this.updateProgress(85, 'Formatting transcript...');
                
                // Prepare audio player
                const audioUrl = URL.createObjectURL(this.audioBlob);
                this.audioPlayer.src = audioUrl;

                this.applySpeakerNames();
                
                this.updateStep('step-format', 'completed');
                this.updateProgress(100, 'Processing complete!');
            }

            displayTranscript() {
                this.transcriptContainer.style.display = 'grid';
                this.processingSection.style.display = 'none';
                
                this.renderTranscriptContent();
                this.setupTranscriptInteractivity();
                this.updateWordCount();
            }

            renderTranscriptContent() {
                const segments = this.transcriptData.segments;
                let html = '';
                
                segments.forEach((segment, segmentIndex) => {
                    html += `
                        <div class="speaker-segment" data-segment="${segmentIndex}">
                            <div class="speaker-label" contenteditable="true">${segment.speaker}</div>
                            <div class="transcript-text">
                    `;
                    
                    segment.words.forEach((word, wordIndex) => {
                        const confidence = this.getConfidenceClass(word.confidence);
                        const globalIndex = segmentIndex * 1000 + wordIndex; // Unique index
                        
                        html += `
                            <span class="transcript-word ${confidence}" 
                                  data-time="${word.start}" 
                                  data-duration="${word.end - word.start}"
                                  data-confidence="${word.confidence}"
                                  data-word-index="${globalIndex}">
                                ${word.text}
                            </span>
                        `;
                    });
                    
                    html += `
                            <span class="timestamp">[${this.formatTime(segment.start)} - ${this.formatTime(segment.end)}]</span>
                            </div>
                        </div>
                    `;
                });
                
                this.transcriptContent.innerHTML = html;
            }

            getConfidenceClass(confidence) {
                if (confidence >= 0.8) return 'confidence-high';
                if (confidence >= 0.6) return 'confidence-medium';
                return 'confidence-low low-confidence';
            }

            setupTranscriptInteractivity() {
                // Word click events
                this.transcriptContent.addEventListener('click', (e) => {
                    if (e.target.classList.contains('transcript-word')) {
                        const time = parseFloat(e.target.dataset.time);
                        this.audioPlayer.currentTime = time;
                        if (this.playOnClick) {
                            this.audioPlayer.play();
                        }
                    }
                });
                
                // Audio time update
                this.audioPlayer.addEventListener('timeupdate', () => {
                    this.updateCurrentWord();
                });
                
                // Speaker label editing
                this.transcriptContent.addEventListener('blur', (e) => {
                    if (e.target.classList.contains('speaker-label')) {
                        this.updateSpeakerLabels(e.target);
                    }
                }, true);
            }

            updateCurrentWord() {
                const currentTime = this.audioPlayer.currentTime;
                const words = this.transcriptContent.querySelectorAll('.transcript-word');
                let newCurrentWord = null;
                
                words.forEach(word => {
                    const startTime = parseFloat(word.dataset.time);
                    const duration = parseFloat(word.dataset.duration);
                    
                    if (currentTime >= startTime && currentTime < startTime + duration) {
                        newCurrentWord = word;
                    }
                });
                
                // Remove previous current word highlighting
                const previousCurrent = this.transcriptContent.querySelector('.transcript-word.current');
                if (previousCurrent) {
                    previousCurrent.classList.remove('current');
                }
                
                // Add current word highlighting
                if (newCurrentWord) {
                    newCurrentWord.classList.add('current');
                    
                    if (this.autoScroll) {
                        newCurrentWord.scrollIntoView({
                            behavior: 'smooth',
                            block: 'center'
                        });
                    }
                }
            }

            updateSpeakerLabels(editedLabel) {
                const segment = editedLabel.closest('.speaker-segment');
                const segmentIndex = parseInt(segment.dataset.segment);
                const newSpeakerName = editedLabel.textContent.trim();

                // Update in data structure
                this.transcriptData.segments[segmentIndex].speaker = newSpeakerName;
            }

            applySpeakerNames() {
                const names = this.speakerNames.value.split(',').map(n => n.trim()).filter(Boolean);
                this.transcriptData.segments.forEach(seg => {
                    const match = seg.speaker.match(/(\d+)/);
                    if (match) {
                        const idx = parseInt(match[1]) - 1;
                        if (names[idx]) seg.speaker = names[idx];
                    }
                });
            }

            togglePlayOnClick() {
                this.playOnClick = !this.playOnClick;
                this.playOnClickBtn.classList.toggle('active', this.playOnClick);
            }

            toggleAutoScroll() {
                this.autoScroll = !this.autoScroll;
                this.autoScrollBtn.classList.toggle('active', this.autoScroll);
            }

            setPlaybackSpeed(speed) {
                this.audioPlayer.playbackRate = parseFloat(speed);
                
                // Update active button
                document.querySelectorAll('[id^="speed-"]').forEach(btn => {
                    btn.classList.remove('active');
                });
                document.getElementById(`speed-${speed.replace('.', '')}x`).classList.add('active');
            }

            handleSearch(e) {
                const query = e.target.value.toLowerCase();
                const words = this.transcriptContent.querySelectorAll('.transcript-word');
                
                words.forEach(word => {
                    const text = word.textContent.toLowerCase();
                    if (query && text.includes(query)) {
                        word.style.backgroundColor = '#ffeaa7';
                    } else {
                        word.style.backgroundColor = '';
                    }
                });
            }

            updateWordCount() {
                const words = this.transcriptContent.querySelectorAll('.transcript-word');
                this.wordCount.textContent = `${words.length} words`;
            }

            exportTranscript(format) {
                if (!this.transcriptData) return;
                
                let content = '';
                let filename = `transcript.${format}`;
                let mimeType = 'text/plain';
                
                switch (format) {
                    case 'txt':
                        content = this.generateTextExport();
                        break;
                    case 'srt':
                        content = this.generateSRTExport();
                        mimeType = 'application/x-subrip';
                        break;
                    case 'vtt':
                        content = this.generateVTTExport();
                        mimeType = 'text/vtt';
                        break;
                    case 'json':
                        content = JSON.stringify(this.transcriptData, null, 2);
                        mimeType = 'application/json';
                        break;
                    case 'html':
                        content = this.generateHTMLExport();
                        mimeType = 'text/html';
                        break;
                }
                
                this.downloadFile(content, filename, mimeType);
            }

            generateTextExport() {
                return this.transcriptData.segments.map(segment => {
                    const text = segment.words.map(word => word.text).join(' ');
                    return `${segment.speaker}: ${text}`;
                }).join('\n\n');
            }

            generateSRTExport() {
                let srt = '';
                let counter = 1;
                
                this.transcriptData.segments.forEach(segment => {
                    const text = segment.words.map(word => word.text).join(' ');
                    const start = this.formatSRTTime(segment.start);
                    const end = this.formatSRTTime(segment.end);
                    
                    srt += `${counter}\n${start} --> ${end}\n${segment.speaker}: ${text}\n\n`;
                    counter++;
                });
                
                return srt;
            }

            generateVTTExport() {
                let vtt = 'WEBVTT\n\n';
                
                this.transcriptData.segments.forEach(segment => {
                    const text = segment.words.map(word => word.text).join(' ');
                    const start = this.formatVTTTime(segment.start);
                    const end = this.formatVTTTime(segment.end);
                    
                    vtt += `${start} --> ${end}\n${segment.speaker}: ${text}\n\n`;
                });
                
                return vtt;
            }

            generateHTMLExport() {
                const content = this.transcriptContent.innerHTML;
                return `
                    <!DOCTYPE html>
                    <html>
                    <head>
                        <title>Transcript Export</title>
                        <meta charset="utf-8">
                        <style>
                            body { font-family: Arial, sans-serif; line-height: 1.6; margin: 40px; }
                            .speaker-label { font-weight: bold; color: #2c3e50; margin-top: 20px; }
                            .transcript-text { margin-bottom: 15px; }
                            .timestamp { color: #7f8c8d; font-size: 0.9em; }
                            .low-confidence { background-color: #ffebee; }
                        </style>
                    </head>
                    <body>
                        <h1>Transcript Report</h1>
                        <p><strong>Generated:</strong> ${new Date().toLocaleString()}</p>
                        <p><strong>Language:</strong> ${this.transcriptData.language || 'Auto-detected'}</p>
                        <hr>
                        ${content}
                    </body>
                    </html>
                `;
            }

            formatTime(seconds) {
                const mins = Math.floor(seconds / 60);
                const secs = Math.floor(seconds % 60);
                return `${mins}:${secs.toString().padStart(2, '0')}`;
            }

            formatSRTTime(seconds) {
                const hours = Math.floor(seconds / 3600);
                const minutes = Math.floor((seconds % 3600) / 60);
                const secs = Math.floor(seconds % 60);
                const ms = Math.floor((seconds % 1) * 1000);
                return `${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')},${ms.toString().padStart(3, '0')}`;
            }

            formatVTTTime(seconds) {
                const hours = Math.floor(seconds / 3600);
                const minutes = Math.floor((seconds % 3600) / 60);
                const secs = Math.floor(seconds % 60);
                const ms = Math.floor((seconds % 1) * 1000);
                return `${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}.${ms.toString().padStart(3, '0')}`;
            }

            downloadFile(content, filename, mimeType) {
                const blob = new Blob([content], { type: mimeType });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = filename;
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
            }

            updateStep(stepId, status) {
                const step = document.getElementById(stepId);
                step.className = `process-step ${status}`;
            }

            updateProgress(percent, message) {
                this.progressFill.style.width = `${percent}%`;
                this.statusMessage.innerHTML = `<div class="loading-spinner"></div> ${message}`;
            }

            updateServiceOptions() {
                const service = this.transcriptionService.value;
                const diarizationOption = this.speakerDiarization;
                
                if (service === 'openai') {
                    // OpenAI doesn't have built-in diarization
                    diarizationOption.innerHTML = `
                        <option value="false">No (OpenAI doesn't support diarization)</option>
                        <option value="true">Post-process (Experimental)</option>
                    `;
                } else {
                    // AssemblyAI supports diarization
                    diarizationOption.innerHTML = `
                        <option value="true">Yes</option>
                        <option value="false">No</option>
                    `;
                }
            }

            showError(message) {
                this.statusMessage.innerHTML = `<div class="error-message">${message}</div>`;
            }

            showSuccess(message) {
                this.statusMessage.innerHTML = `<div class="success-message">${message}</div>`;
            }
        }

        // Initialize the application
        document.addEventListener('DOMContentLoaded', () => {
            new AdvancedTranscriptionStudio();
        });
    </script>
</body>
</html>
